#!/usr/bin/env python3
"""
Script test Airflow DAG k·∫øt n·ªëi Kafka
"""

import os
import sys
import logging
from datetime import datetime

# Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ import c√°c module
sys.path.append(os.path.join(os.path.dirname(__file__), '../../include'))

# C·∫•u h√¨nh logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_kafka_producer_task():
    """Test kafka producer task t·ª´ Airflow DAG"""
    logger.info("=== TEST: Kafka Producer Task ===")
    
    try:
        from iot_streaming.kafka_producer_streaming import kafka_run
        
        # Mock context cho Airflow
        context = {
            'ti': MockTaskInstance(),
            'dag': None,
            'task': None
        }
        
        logger.info("üöÄ Ch·∫°y kafka_producer_task...")
        kafka_run(**context)
        
        logger.info("‚úÖ Kafka producer task ch·∫°y th√†nh c√¥ng!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói kafka producer task: {e}")
        return False

def test_kafka_consumer_task():
    """Test kafka consumer task t·ª´ Airflow DAG"""
    logger.info("=== TEST: Kafka Consumer Task ===")
    
    try:
        from iot_streaming.kafka_consumer import kafka_consumer_task
        
        # Mock context cho Airflow
        context = {
            'ti': MockTaskInstance(),
            'dag': None,
            'task': None
        }
        
        logger.info("üöÄ Ch·∫°y kafka_consumer_task...")
        kafka_consumer_task(**context)
        
        logger.info("‚úÖ Kafka consumer task ch·∫°y th√†nh c√¥ng!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói kafka consumer task: {e}")
        return False

def test_database_manager():
    """Test database manager"""
    logger.info("=== TEST: Database Manager ===")
    
    try:
        from iot_streaming.database_manager import db_manager
        
        logger.info("üöÄ Ki·ªÉm tra k·∫øt n·ªëi database...")
        
        # Test k·∫øt n·ªëi
        connection = db_manager.get_connection()
        if connection:
            logger.info("‚úÖ K·∫øt n·ªëi database th√†nh c√¥ng!")
            connection.close()
        else:
            logger.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi database")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói database manager: {e}")
        return False

class MockTaskInstance:
    """Mock class ƒë·ªÉ simulate Airflow TaskInstance"""
    
    def __init__(self):
        self.xcom_data = {}
    
    def xcom_push(self, key, value):
        """Mock xcom_push method"""
        self.xcom_data[key] = value
        logger.info(f"üì§ XCom push: {key} = {value}")
    
    def xcom_pull(self, task_ids=None, key=None):
        """Mock xcom_pull method"""
        if key in self.xcom_data:
            return self.xcom_data[key]
        return None

def check_airflow_environment():
    """Ki·ªÉm tra m√¥i tr∆∞·ªùng Airflow"""
    logger.info("=== KI·ªÇM TRA M√îI TR∆Ø·ªúNG AIRFLOW ===")
    
    # Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng Airflow
    airflow_home = os.getenv('AIRFLOW_HOME')
    if airflow_home:
        logger.info(f"‚úÖ AIRFLOW_HOME: {airflow_home}")
    else:
        logger.warning("‚ö†Ô∏è AIRFLOW_HOME kh√¥ng ƒë∆∞·ª£c set")
    
    # Ki·ªÉm tra th∆∞ m·ª•c dags
    dags_folder = os.path.join(os.path.dirname(__file__), '../../dags')
    if os.path.exists(dags_folder):
        logger.info(f"‚úÖ DAGs folder: {dags_folder}")
    else:
        logger.warning(f"‚ö†Ô∏è DAGs folder kh√¥ng t·ªìn t·∫°i: {dags_folder}")
    
    # Ki·ªÉm tra th∆∞ m·ª•c include
    include_folder = os.path.join(os.path.dirname(__file__), '../../include')
    if os.path.exists(include_folder):
        logger.info(f"‚úÖ Include folder: {include_folder}")
    else:
        logger.warning(f"‚ö†Ô∏è Include folder kh√¥ng t·ªìn t·∫°i: {include_folder}")

def main():
    """Ch·∫°y t·∫•t c·∫£ c√°c test"""
    logger.info("üöÄ B·∫Øt ƒë·∫ßu test Airflow Kafka DAG")
    logger.info("=" * 60)
    
    # Ki·ªÉm tra m√¥i tr∆∞·ªùng
    check_airflow_environment()
    logger.info("")
    
    results = []
    
    # Test c√°c component
    results.append(("Database Manager", test_database_manager()))
    results.append(("Kafka Producer Task", test_kafka_producer_task()))
    results.append(("Kafka Consumer Task", test_kafka_consumer_task()))
    
    # T·ªïng k·∫øt
    logger.info("=" * 60)
    logger.info("üìä K·∫æT QU·∫¢ TEST AIRFLOW DAG:")
    
    passed = 0
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        logger.info(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"üìà T·ªïng k·∫øt: {passed}/{total} test th√†nh c√¥ng")
    
    if passed == total:
        logger.info("üéâ T·∫•t c·∫£ Airflow DAG test ƒë·ªÅu th√†nh c√¥ng!")
    else:
        logger.warning("‚ö†Ô∏è M·ªôt s·ªë test th·∫•t b·∫°i. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh.")
    
    logger.info("=" * 60)

if __name__ == "__main__":
    main() 