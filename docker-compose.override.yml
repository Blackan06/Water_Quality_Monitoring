
services:

  # Kafka Zookeeper
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ZOOKEEPER_TICK_TIME=2000
      - ZOOKEEPER_INIT_LIMIT=5
      - ZOOKEEPER_SYNC_LIMIT=2
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - bigdata-network

  # Kafka Broker
  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions.sh", "--bootstrap-server", "kafka:9092"]
      interval: 30s
      retries: 3
      start_period: 10s
      timeout: 5s
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092  
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL=PLAINTEXT
      - KAFKA_CFG_LISTENER_PORT=9092
      - KAFKA_CFG_LISTENER_NAME=PLAINTEXT
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    depends_on:
      - zookeeper
    networks:
      - bigdata-network

  # Elasticsearch
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - ELASTIC_PASSWORD=elasticpassword
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - bigdata-network
    ulimits:
      memlock:
        soft: -1
        hard: -1

  # Kibana (For visualizing Elasticsearch data)
  kibana:
    image: docker.elastic.co/kibana/kibana:7.10.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=elasticpassword
    ports:
      - "5601:5601"  # Kibana UI
    depends_on:
      - elasticsearch
    networks:
      - bigdata-network

  # Kafka Producer App
  kafka_producer:
    build:
      context: .  
      dockerfile: kafka/producer/Dockerfile  
    container_name: kafka_producer
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=water-quality-data
      - DB_HOST=postgres
      - DB_USER=postgres
      - DB_PASSWORD=admin1234
      - DB_NAME=WQI
    depends_on:
      - kafka
    networks:
      - bigdata-network

  # Spark Master and Worker Nodes
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "8080:8080"  # Spark UI
      - "7077:7077"  # Spark master port
    volumes:
      - spark_checkpoint:/tmp/spark/checkpoint
      - spark_commit_log:/tmp/spark/commit_log
    networks:
      - bigdata-network

  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8081:8081"
    networks:
      - bigdata-network

  # Kafka UI (Lenses.io)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8085:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local-cluster
      - KAFKA_CLUSTERS_0_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_UI_AUTH_TYPE=BASIC
      - KAFKA_UI_AUTH_USERNAME=admin
      - KAFKA_UI_AUTH_PASSWORD=admin1234
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - bigdata-network
  spark-consumer:
      build:
          context: .
          dockerfile: spark/Dockerfile
      container_name: spark-consumer
      env_file:
        - .env      
      depends_on:
        - kafka
        - spark-master
      networks:
        - bigdata-network


networks:
  bigdata-network:
    driver: bridge

volumes:
  postgres_data:
  elasticsearch_data:
  spark_checkpoint:
  spark_commit_log:
